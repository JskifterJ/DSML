{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3291378f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (14767993, 9)\n",
      "Columns: ['Country', 'Samplingpoint', 'Pollutant', 'Start', 'End', 'Value', 'Unit', 'AggType', 'Notation']\n",
      "\n",
      "Head:\n",
      "  Country           Samplingpoint  Pollutant                Start  \\\n",
      "0      NO  NO/SPO_NO0073A_38_1785         38  2019-01-01 00:00:00   \n",
      "1      NO  NO/SPO_NO0073A_38_1785         38  2019-01-01 01:00:00   \n",
      "2      NO  NO/SPO_NO0073A_38_1785         38  2019-01-01 02:00:00   \n",
      "3      NO  NO/SPO_NO0073A_38_1785         38  2019-01-01 03:00:00   \n",
      "4      NO  NO/SPO_NO0073A_38_1785         38  2019-01-01 04:00:00   \n",
      "\n",
      "                   End   Value    Unit AggType Notation  \n",
      "0  2019-01-01 01:00:00 -9900.0  ug.m-3    hour     PM10  \n",
      "1  2019-01-01 02:00:00 -9900.0  ug.m-3    hour     PM10  \n",
      "2  2019-01-01 03:00:00 -9900.0  ug.m-3    hour     PM10  \n",
      "3  2019-01-01 04:00:00 -9900.0  ug.m-3    hour     PM10  \n",
      "4  2019-01-01 05:00:00 -9900.0  ug.m-3    hour     PM10  \n",
      "\n",
      "Summary statistics:\n",
      "         Country          Samplingpoint     Pollutant                Start  \\\n",
      "count   14767993               14767993  1.476799e+07             14767993   \n",
      "unique         5                    199           NaN                96409   \n",
      "top           AT  NO/SPO_NO0093A_8_1042           NaN  2022-01-01 15:00:00   \n",
      "freq     4374113                  96408           NaN                  190   \n",
      "mean         NaN                    NaN  9.038945e+02                  NaN   \n",
      "std          NaN                    NaN  2.130238e+03                  NaN   \n",
      "min          NaN                    NaN  5.000000e+00                  NaN   \n",
      "25%          NaN                    NaN  7.000000e+00                  NaN   \n",
      "50%          NaN                    NaN  8.000000e+00                  NaN   \n",
      "75%          NaN                    NaN  3.800000e+01                  NaN   \n",
      "max          NaN                    NaN  6.001000e+03                  NaN   \n",
      "\n",
      "                        End         Value      Unit   AggType  Notation  \n",
      "count              14767993  1.476799e+07  14767993  14767993  14767993  \n",
      "unique                96409           NaN         1         1         6  \n",
      "top     2022-01-01 16:00:00           NaN    ug.m-3      hour       NO2  \n",
      "freq                    190           NaN  14767993  14767993   3779641  \n",
      "mean                    NaN -2.116533e+03       NaN       NaN       NaN  \n",
      "std                     NaN  6.085374e+06       NaN       NaN       NaN  \n",
      "min                     NaN -1.167965e+10       NaN       NaN       NaN  \n",
      "25%                     NaN  6.212550e+00       NaN       NaN       NaN  \n",
      "50%                     NaN  1.510785e+01       NaN       NaN       NaN  \n",
      "75%                     NaN  3.314390e+01       NaN       NaN       NaN  \n",
      "max                     NaN  1.183894e+10       NaN       NaN       NaN  \n",
      "\n",
      "Missing values per column:\n",
      "Country          0\n",
      "Samplingpoint    0\n",
      "Pollutant        0\n",
      "Start            0\n",
      "End              0\n",
      "Value            0\n",
      "Unit             0\n",
      "AggType          0\n",
      "Notation         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the air quality merged data\n",
    "aq_df = pd.read_csv(\"../data/processed/AQ_merged_data_export.csv\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"Shape:\", aq_df.shape)\n",
    "print(\"Columns:\", aq_df.columns.tolist())\n",
    "print(\"\\nHead:\")\n",
    "print(aq_df.head())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(aq_df.describe(include='all'))\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(aq_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f32cb175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Country        Date    Notation  Daily_Avg  Daytime_Avg  RushHour_Avg\n",
      "0      AT  2009-01-01         NO2  35.525558          NaN           NaN\n",
      "1      AT  2013-01-01         CO2  35.851000    38.626760     37.535657\n",
      "2      AT  2013-01-01          NO  80.641822    52.104975     51.446887\n",
      "3      AT  2013-01-01         NO2  26.560859    22.000584     24.580176\n",
      "4      AT  2013-01-01  NOX as NO2  53.923347    45.303470     44.564314\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the merged air quality data\n",
    "aq_df = pd.read_csv(\"../data/processed/AQ_merged_data_export.csv\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "aq_cleaned = aq_df.drop(columns=['Samplingpoint', 'Pollutant', 'AggType'], errors='ignore')\n",
    "\n",
    "# Keep only the 'End' column for datetime\n",
    "aq_cleaned = aq_cleaned.rename(columns={'End': 'Datetime'})\n",
    "if 'Start' in aq_cleaned.columns:\n",
    "    aq_cleaned = aq_cleaned.drop(columns=['Start'])\n",
    "\n",
    "# Convert 'Datetime' to pandas datetime\n",
    "aq_cleaned['Datetime'] = pd.to_datetime(aq_cleaned['Datetime'], errors='coerce')\n",
    "aq_cleaned = aq_cleaned.dropna(subset=['Datetime'])\n",
    "\n",
    "# Extract date and hour for grouping\n",
    "aq_cleaned['Date'] = aq_cleaned['Datetime'].dt.date\n",
    "aq_cleaned['Hour'] = aq_cleaned['Datetime'].dt.hour\n",
    "\n",
    "# Daily average per country\n",
    "daily_avg = aq_cleaned.groupby(['Country', 'Date', 'Notation'])['Value'].mean().reset_index()\n",
    "daily_avg = daily_avg.rename(columns={'Value': 'Daily_Avg'})\n",
    "\n",
    "# Daytime average (9-18 End time, i.e., 8-17 actual hour)\n",
    "daytime_mask = aq_cleaned['Hour'].between(9, 18)\n",
    "daytime_avg = aq_cleaned[daytime_mask].groupby(['Country', 'Date', 'Notation'])['Value'].mean().reset_index()\n",
    "daytime_avg = daytime_avg.rename(columns={'Value': 'Daytime_Avg'})\n",
    "\n",
    "# Rush-hour average (8-10 and 15-18 End time, i.e., 7-9 and 15-17 actual hour)\n",
    "rush_mask = (aq_cleaned['Hour'].between(8, 10)) | (aq_cleaned['Hour'].between(15, 18))\n",
    "rush_avg = aq_cleaned[rush_mask].groupby(['Country', 'Date', 'Notation'])['Value'].mean().reset_index()\n",
    "rush_avg = rush_avg.rename(columns={'Value': 'RushHour_Avg'})\n",
    "\n",
    "# Merge all averages into one DataFrame\n",
    "aq_merged_cleaned = daily_avg.merge(daytime_avg, on=['Country', 'Date', 'Notation'], how='left')\n",
    "aq_merged_cleaned = aq_merged_cleaned.merge(rush_avg, on=['Country', 'Date', 'Notation'], how='left')\n",
    "\n",
    "# Save the cleaned dataset\n",
    "aq_merged_cleaned.to_csv(\"../data/processed/AQ_merged_cleaned.csv\", index=False)\n",
    "\n",
    "print(aq_merged_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3994de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jskif\\AppData\\Local\\Temp\\ipykernel_18920\\3582149203.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df = df[mask]\n",
      "C:\\Users\\jskif\\AppData\\Local\\Temp\\ipykernel_18920\\3582149203.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df = df[mask]\n",
      "C:\\Users\\jskif\\AppData\\Local\\Temp\\ipykernel_18920\\3582149203.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df = df[mask]\n",
      "C:\\Users\\jskif\\AppData\\Local\\Temp\\ipykernel_18920\\3582149203.py:25: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df = df[mask]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Country Pollutant  Year  AnnualAvg_fullweek_Daytime  \\\n",
      "0      AT       CO2  2013                   60.556376   \n",
      "1      AT       CO2  2014                   56.194409   \n",
      "2      AT       CO2  2015                   65.263546   \n",
      "3      AT       CO2  2016                   61.306118   \n",
      "4      AT       CO2  2017                   65.076009   \n",
      "\n",
      "   AnnualAvg_fullweek_RushHour  AnnualAvg_weekday_Daytime  \\\n",
      "0                    54.747262                  58.785469   \n",
      "1                    50.201177                  54.746705   \n",
      "2                    58.792255                  62.895737   \n",
      "3                    54.839356                  59.180094   \n",
      "4                    59.085989                  63.561608   \n",
      "\n",
      "   AnnualAvg_weekday_RushHour  AnnualAvg_weekend_Daytime  \\\n",
      "0                   52.816588                  65.000672   \n",
      "1                   48.623885                  59.827592   \n",
      "2                   56.234633                  71.205836   \n",
      "3                   52.795785                  66.590806   \n",
      "4                   57.291473                  68.823805   \n",
      "\n",
      "   AnnualAvg_weekend_RushHour  \n",
      "0                   59.592510  \n",
      "1                   54.159573  \n",
      "2                   65.210903  \n",
      "3                   59.919090  \n",
      "4                   63.527005  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the merged air quality data\n",
    "aq_df = pd.read_csv(\"../data/processed/AQ_merged_data_export.csv\")\n",
    "\n",
    "# Prepare datetime and helper columns\n",
    "aq_df['Datetime'] = pd.to_datetime(aq_df['End'], errors='coerce')\n",
    "aq_df = aq_df.dropna(subset=['Datetime'])\n",
    "aq_df['Year'] = aq_df['Datetime'].dt.year\n",
    "aq_df['Hour'] = aq_df['Datetime'].dt.hour\n",
    "aq_df['Weekday'] = aq_df['Datetime'].dt.weekday  # 0=Monday, ..., 6=Sunday\n",
    "aq_df['IsWeekend'] = aq_df['Weekday'] >= 5\n",
    "\n",
    "# Helper masks\n",
    "daytime_mask = aq_df['Hour'].between(9, 18)  # End time 9-18 (i.e., 8-17 actual hour)\n",
    "rush_mask = (aq_df['Hour'].between(8, 10)) | (aq_df['Hour'].between(16, 18))  # End time 8-10, 15-18\n",
    "\n",
    "def annual_avg(df, mask, period):\n",
    "    # period: 'fullweek', 'weekday', 'weekend'\n",
    "    if period == 'weekday':\n",
    "        df = df[~df['IsWeekend']]\n",
    "    elif period == 'weekend':\n",
    "        df = df[df['IsWeekend']]\n",
    "    df = df[mask]\n",
    "    return (\n",
    "        df.groupby(['Country', 'Notation', 'Year'])['Value']\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={'Value': f'AnnualAvg_{period}'})\n",
    "    )\n",
    "\n",
    "# Compute all combinations\n",
    "results = []\n",
    "\n",
    "for period in ['fullweek', 'weekday', 'weekend']:\n",
    "    # Daytime\n",
    "    dt_avg = annual_avg(aq_df, daytime_mask, period)\n",
    "    dt_avg['Type'] = 'Daytime'\n",
    "    results.append(dt_avg)\n",
    "    # Rush-hour\n",
    "    rh_avg = annual_avg(aq_df, rush_mask, period)\n",
    "    rh_avg['Type'] = 'RushHour'\n",
    "    results.append(rh_avg)\n",
    "\n",
    "# Concatenate and pivot for clarity\n",
    "annual_averages = pd.concat(results, ignore_index=True)\n",
    "annual_averages = annual_averages.pivot_table(\n",
    "    index=['Country', 'Notation', 'Year'],\n",
    "    columns=['Type'],\n",
    "    values=['AnnualAvg_fullweek', 'AnnualAvg_weekday', 'AnnualAvg_weekend']\n",
    ").reset_index()\n",
    "\n",
    "# Flatten columns\n",
    "annual_averages.columns = ['_'.join([str(i) for i in col if i]) for col in annual_averages.columns.values]\n",
    "\n",
    "# rename notation column to 'Pollutant'\n",
    "annual_averages = annual_averages.rename(columns={'Notation': 'Pollutant'})\n",
    "\n",
    "# Save to processed folder\n",
    "annual_averages.to_csv(\"../data/processed/AQ_annual_averages.csv\", index=False)\n",
    "\n",
    "print(annual_averages.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsml_EV_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
